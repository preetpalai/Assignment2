{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a437772f",
   "metadata": {},
   "source": [
    "### CSCN8020 – Assignment 2: Q-Learning on Taxi-v3\n",
    "\n",
    "**Student:** Preetpal Singh  \n",
    "\n",
    "**StudentID:** 8804336\n",
    "\n",
    "\n",
    "This notebook satisfies the required deliverables:\n",
    "- Q-Learning implementation\n",
    "- Baseline + hyperparameter sweeps\n",
    "- Metrics/plots + best configuration selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8077e73",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Run once on your local machine to install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00a8f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium[toy_text]) (2.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If already installed, you can skip.\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install gymnasium \"gymnasium[toy_text]\" numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d379cb4",
   "metadata": {},
   "source": [
    "## 1) Q-Learning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80bf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, json, csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "def epsilon_greedy(q, s, epsilon, n_actions, rng):\n",
    "    if rng.random() < epsilon:\n",
    "        return rng.integers(0, n_actions)\n",
    "    return int(np.argmax(q[s]))\n",
    "\n",
    "def q_learning(env_name=\"Taxi-v3\", episodes=5000, alpha=0.1, gamma=0.9, epsilon=0.1, seed=42, render_every=None):\n",
    "    env = gym.make(env_name)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    q = np.zeros((n_states, n_actions), dtype=np.float32)\n",
    "    ep_returns, ep_lengths = [], []\n",
    "    for ep in range(episodes):\n",
    "        s, info = env.reset(seed=seed + ep)\n",
    "        done = False\n",
    "        total_return = 0.0\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            a = epsilon_greedy(q, s, epsilon, n_actions, rng)\n",
    "            s2, r, terminated, truncated, info = env.step(a)\n",
    "            done = terminated or truncated\n",
    "            td_target = r + gamma * np.max(q[s2]) * (0.0 if done else 1.0)\n",
    "            td_error = td_target - q[s, a]\n",
    "            q[s, a] += alpha * td_error\n",
    "            total_return += r\n",
    "            s = s2\n",
    "            steps += 1\n",
    "        ep_returns.append(total_return)\n",
    "        ep_lengths.append(steps)\n",
    "        if render_every is not None and (ep+1) % render_every == 0:\n",
    "            print(f\"[{ep+1:5d}/{episodes}] Return={total_return:.1f}, Steps={steps}\")\n",
    "    env.close()\n",
    "    return q, np.array(ep_returns, dtype=np.float32), np.array(ep_lengths, dtype=np.int32)\n",
    "\n",
    "def moving_avg(x, k=50):\n",
    "    if len(x) < k:\n",
    "        return x.copy()\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[k:] - cumsum[:-k]) / float(k)\n",
    "\n",
    "def run_and_log(episodes, alpha, gamma, epsilon, outdir, tag, seed=42):\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    t0 = time.time()\n",
    "    q, returns, lengths = q_learning(episodes=episodes, alpha=alpha, gamma=gamma, epsilon=epsilon, seed=seed)\n",
    "    dt = time.time() - t0\n",
    "    avg_returns = moving_avg(returns, k=min(50, len(returns)))\n",
    "\n",
    "    # CSV\n",
    "    csv_path = outdir / f\"{tag}_metrics.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"episode\", \"return\", \"steps\"])\n",
    "        for i, (r, s) in enumerate(zip(returns, lengths), start=1):\n",
    "            writer.writerow([i, float(r), int(s)])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.plot(returns, label=\"Return per episode\")\n",
    "    if len(avg_returns) > 0:\n",
    "        import numpy as _np\n",
    "        x = _np.arange(len(avg_returns)) + 1 + (len(returns) - len(avg_returns))\n",
    "        plt.plot(x, avg_returns, label=\"Moving average (window=50)\")\n",
    "    plt.xlabel(\"Episode\"); plt.ylabel(\"Return\")\n",
    "    plt.title(f\"Taxi-v3 Q-Learning | α={alpha}, ε={epsilon}, γ={gamma}\")\n",
    "    plt.legend()\n",
    "    plot_path = outdir / f\"{tag}_plots.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "    # Q-table\n",
    "    np.save(outdir / f\"{tag}_qtable.npy\", q)\n",
    "\n",
    "    summary = {\n",
    "        \"episodes\": int(episodes),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"epsilon\": float(epsilon),\n",
    "        \"gamma\": float(gamma),\n",
    "        \"mean_return\": float(np.mean(returns[-100:])) if len(returns) >= 100 else float(np.mean(returns)),\n",
    "        \"mean_steps\": float(np.mean(lengths[-100:])) if len(lengths) >= 100 else float(np.mean(lengths)),\n",
    "        \"train_time_sec\": float(dt),\n",
    "        \"csv_path\": str(csv_path),\n",
    "        \"plot_path\": str(plot_path),\n",
    "    }\n",
    "    with open(outdir / f\"{tag}_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved: {csv_path.name}, {plot_path.name}\")\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b400bc",
   "metadata": {},
   "source": [
    "## 2) Run Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3efdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: runs\\20251016-210618\n",
      "Saved: base_a0.1_e0.1_g0.9_metrics.csv, base_a0.1_e0.1_g0.9_plots.png\n",
      "Baseline complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path, PurePosixPath\n",
    "import time, json\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "outdir = Path(\"runs\") / timestamp\n",
    "print(\"Output dir:\", outdir)\n",
    "\n",
    "base = run_and_log(episodes=5000, alpha=0.1, gamma=0.9, epsilon=0.1, outdir=outdir, tag=f\"base_a0.1_e0.1_g0.9\")\n",
    "\n",
    "# Save overall_summary.json scaffold (will be updated by sweeps below)\n",
    "with open(outdir / \"overall_summary.json\", \"w\") as f:\n",
    "    json.dump({\"best\": base, \"runs\": [base]}, f, indent=2)\n",
    "print(\"Baseline complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb1c68",
   "metadata": {},
   "source": [
    "## 3) Hyperparameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad43a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: sweep_alpha_0.01_metrics.csv, sweep_alpha_0.01_plots.png\n",
      "Saved: sweep_alpha_0.001_metrics.csv, sweep_alpha_0.001_plots.png\n",
      "Saved: sweep_alpha_0.2_metrics.csv, sweep_alpha_0.2_plots.png\n",
      "Saved: sweep_epsilon_0.2_metrics.csv, sweep_epsilon_0.2_plots.png\n",
      "Saved: sweep_epsilon_0.3_metrics.csv, sweep_epsilon_0.3_plots.png\n",
      "Best configuration: {'episodes': 5000, 'alpha': 0.1, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': 1.9800000190734863, 'mean_steps': 15.06, 'train_time_sec': 17.96415615081787, 'csv_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_plots.png'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "# Learning-rate sweep\n",
    "lr_runs = []\n",
    "for a in [0.01, 0.001, 0.2]:\n",
    "    lr_runs.append(run_and_log(episodes=5000, alpha=a, gamma=0.9, epsilon=0.1, outdir=outdir, tag=f\"sweep_alpha_{a}\"))\n",
    "\n",
    "# Exploration sweep\n",
    "eps_runs = []\n",
    "for e in [0.2, 0.3]:\n",
    "    eps_runs.append(run_and_log(episodes=5000, alpha=0.1, gamma=0.9, epsilon=e, outdir=outdir, tag=f\"sweep_epsilon_{e}\"))\n",
    "\n",
    "# Compute best\n",
    "all_runs = [base] + lr_runs + eps_runs\n",
    "best = max(all_runs, key=lambda d: d[\"mean_return\"])\n",
    "\n",
    "with open(outdir / \"overall_summary.json\", \"w\") as f:\n",
    "    json.dump({\"best\": best, \"runs\": all_runs}, f, indent=2)\n",
    "\n",
    "print(\"Best configuration:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86160fa3",
   "metadata": {},
   "source": [
    "## 4) Load Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4e721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest run folder: runs\\20251016-210618\n",
      "\n",
      "Best configuration:\n",
      "{'episodes': 5000, 'alpha': 0.1, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': 1.9800000190734863, 'mean_steps': 15.06, 'train_time_sec': 17.96415615081787, 'csv_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_plots.png'}\n",
      "\n",
      "All runs:\n",
      "{'episodes': 5000, 'alpha': 0.1, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': 1.9800000190734863, 'mean_steps': 15.06, 'train_time_sec': 17.96415615081787, 'csv_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\base_a0.1_e0.1_g0.9_plots.png'}\n",
      "{'episodes': 5000, 'alpha': 0.01, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': -72.22000122070312, 'mean_steps': 70.81, 'train_time_sec': 71.29939150810242, 'csv_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.01_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.01_plots.png'}\n",
      "{'episodes': 5000, 'alpha': 0.001, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': -253.75999450683594, 'mean_steps': 185.84, 'train_time_sec': 124.04832291603088, 'csv_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.001_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.001_plots.png'}\n",
      "{'episodes': 5000, 'alpha': 0.2, 'epsilon': 0.1, 'gamma': 0.9, 'mean_return': 1.9700000286102295, 'mean_steps': 14.98, 'train_time_sec': 5.37880802154541, 'csv_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.2_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\sweep_alpha_0.2_plots.png'}\n",
      "{'episodes': 5000, 'alpha': 0.1, 'epsilon': 0.2, 'gamma': 0.9, 'mean_return': -4.769999980926514, 'mean_steps': 17.31, 'train_time_sec': 7.085123538970947, 'csv_path': 'runs\\\\20251016-210618\\\\sweep_epsilon_0.2_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\sweep_epsilon_0.2_plots.png'}\n",
      "{'episodes': 5000, 'alpha': 0.1, 'epsilon': 0.3, 'gamma': 0.9, 'mean_return': -14.90999984741211, 'mean_steps': 19.98, 'train_time_sec': 7.878866910934448, 'csv_path': 'runs\\\\20251016-210618\\\\sweep_epsilon_0.3_metrics.csv', 'plot_path': 'runs\\\\20251016-210618\\\\sweep_epsilon_0.3_plots.png'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load newest overall_summary.json\n",
    "runs = Path(\"runs\")\n",
    "if runs.exists():\n",
    "    latest = max([p for p in runs.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "    with open(latest / \"overall_summary.json\", \"r\") as f:\n",
    "        overall = json.load(f)\n",
    "    print(\"Newest run folder:\", latest)\n",
    "    print(\"\\nBest configuration:\"); print(overall[\"best\"])\n",
    "    print(\"\\nAll runs:\"); \n",
    "    for r in overall[\"runs\"]:\n",
    "        print(r)\n",
    "else:\n",
    "    print(\"No runs found. Execute the training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb296a7",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Plots & Discussion\n",
    "\n",
    "- Open the `runs/<timestamp>` folder and insert the `*_plots.png` here (Insert → Image).\n",
    "- Discuss observations (convergence, stability, steps trend).\n",
    "- Explain why your chosen (α, ε) performed best.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
