{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a437772f",
   "metadata": {},
   "source": [
    "# CSCN8020 – Assignment 2: Q-Learning on Taxi-v3\n",
    "\n",
    "**Student:** Preetpal Singh &nbsp;&nbsp; **ID:** 8804336 &nbsp;&nbsp; **Date:** 2025-10-16\n",
    "\n",
    "This notebook satisfies the required deliverables:\n",
    "- Q-Learning implementation\n",
    "- Baseline + hyperparameter sweeps\n",
    "- Metrics/plots + best configuration selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8077e73",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "Run once on your local machine to install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If already installed, you can skip.\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install gymnasium \"gymnasium[toy_text]\" numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d379cb4",
   "metadata": {},
   "source": [
    "## 1) Q-Learning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, json, csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "def epsilon_greedy(q, s, epsilon, n_actions, rng):\n",
    "    if rng.random() < epsilon:\n",
    "        return rng.integers(0, n_actions)\n",
    "    return int(np.argmax(q[s]))\n",
    "\n",
    "def q_learning(env_name=\"Taxi-v3\", episodes=5000, alpha=0.1, gamma=0.9, epsilon=0.1, seed=42, render_every=None):\n",
    "    env = gym.make(env_name)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    q = np.zeros((n_states, n_actions), dtype=np.float32)\n",
    "    ep_returns, ep_lengths = [], []\n",
    "    for ep in range(episodes):\n",
    "        s, info = env.reset(seed=seed + ep)\n",
    "        done = False\n",
    "        total_return = 0.0\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            a = epsilon_greedy(q, s, epsilon, n_actions, rng)\n",
    "            s2, r, terminated, truncated, info = env.step(a)\n",
    "            done = terminated or truncated\n",
    "            td_target = r + gamma * np.max(q[s2]) * (0.0 if done else 1.0)\n",
    "            td_error = td_target - q[s, a]\n",
    "            q[s, a] += alpha * td_error\n",
    "            total_return += r\n",
    "            s = s2\n",
    "            steps += 1\n",
    "        ep_returns.append(total_return)\n",
    "        ep_lengths.append(steps)\n",
    "        if render_every is not None and (ep+1) % render_every == 0:\n",
    "            print(f\"[{ep+1:5d}/{episodes}] Return={total_return:.1f}, Steps={steps}\")\n",
    "    env.close()\n",
    "    return q, np.array(ep_returns, dtype=np.float32), np.array(ep_lengths, dtype=np.int32)\n",
    "\n",
    "def moving_avg(x, k=50):\n",
    "    if len(x) < k:\n",
    "        return x.copy()\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[k:] - cumsum[:-k]) / float(k)\n",
    "\n",
    "def run_and_log(episodes, alpha, gamma, epsilon, outdir, tag, seed=42):\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    t0 = time.time()\n",
    "    q, returns, lengths = q_learning(episodes=episodes, alpha=alpha, gamma=gamma, epsilon=epsilon, seed=seed)\n",
    "    dt = time.time() - t0\n",
    "    avg_returns = moving_avg(returns, k=min(50, len(returns)))\n",
    "\n",
    "    # CSV\n",
    "    csv_path = outdir / f\"{tag}_metrics.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"episode\", \"return\", \"steps\"])\n",
    "        for i, (r, s) in enumerate(zip(returns, lengths), start=1):\n",
    "            writer.writerow([i, float(r), int(s)])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.plot(returns, label=\"Return per episode\")\n",
    "    if len(avg_returns) > 0:\n",
    "        import numpy as _np\n",
    "        x = _np.arange(len(avg_returns)) + 1 + (len(returns) - len(avg_returns))\n",
    "        plt.plot(x, avg_returns, label=\"Moving average (window=50)\")\n",
    "    plt.xlabel(\"Episode\"); plt.ylabel(\"Return\")\n",
    "    plt.title(f\"Taxi-v3 Q-Learning | α={alpha}, ε={epsilon}, γ={gamma}\")\n",
    "    plt.legend()\n",
    "    plot_path = outdir / f\"{tag}_plots.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "    # Q-table\n",
    "    np.save(outdir / f\"{tag}_qtable.npy\", q)\n",
    "\n",
    "    summary = {\n",
    "        \"episodes\": int(episodes),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"epsilon\": float(epsilon),\n",
    "        \"gamma\": float(gamma),\n",
    "        \"mean_return\": float(np.mean(returns[-100:])) if len(returns) >= 100 else float(np.mean(returns)),\n",
    "        \"mean_steps\": float(np.mean(lengths[-100:])) if len(lengths) >= 100 else float(np.mean(lengths)),\n",
    "        \"train_time_sec\": float(dt),\n",
    "        \"csv_path\": str(csv_path),\n",
    "        \"plot_path\": str(plot_path),\n",
    "    }\n",
    "    with open(outdir / f\"{tag}_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved: {csv_path.name}, {plot_path.name}\")\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b400bc",
   "metadata": {},
   "source": [
    "## 2) Run Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3efdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path, PurePosixPath\n",
    "import time, json\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "outdir = Path(\"runs\") / timestamp\n",
    "print(\"Output dir:\", outdir)\n",
    "\n",
    "base = run_and_log(episodes=5000, alpha=0.1, gamma=0.9, epsilon=0.1, outdir=outdir, tag=f\"base_a0.1_e0.1_g0.9\")\n",
    "\n",
    "# Save overall_summary.json scaffold (will be updated by sweeps below)\n",
    "with open(outdir / \"overall_summary.json\", \"w\") as f:\n",
    "    json.dump({\"best\": base, \"runs\": [base]}, f, indent=2)\n",
    "print(\"Baseline complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb1c68",
   "metadata": {},
   "source": [
    "## 3) Hyperparameter Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad43a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "# Learning-rate sweep\n",
    "lr_runs = []\n",
    "for a in [0.01, 0.001, 0.2]:\n",
    "    lr_runs.append(run_and_log(episodes=5000, alpha=a, gamma=0.9, epsilon=0.1, outdir=outdir, tag=f\"sweep_alpha_{a}\"))\n",
    "\n",
    "# Exploration sweep\n",
    "eps_runs = []\n",
    "for e in [0.2, 0.3]:\n",
    "    eps_runs.append(run_and_log(episodes=5000, alpha=0.1, gamma=0.9, epsilon=e, outdir=outdir, tag=f\"sweep_epsilon_{e}\"))\n",
    "\n",
    "# Compute best\n",
    "all_runs = [base] + lr_runs + eps_runs\n",
    "best = max(all_runs, key=lambda d: d[\"mean_return\"])\n",
    "\n",
    "with open(outdir / \"overall_summary.json\", \"w\") as f:\n",
    "    json.dump({\"best\": best, \"runs\": all_runs}, f, indent=2)\n",
    "\n",
    "print(\"Best configuration:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86160fa3",
   "metadata": {},
   "source": [
    "## 4) Load Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load newest overall_summary.json\n",
    "runs = Path(\"runs\")\n",
    "if runs.exists():\n",
    "    latest = max([p for p in runs.iterdir() if p.is_dir()], key=lambda p: p.stat().st_mtime)\n",
    "    with open(latest / \"overall_summary.json\", \"r\") as f:\n",
    "        overall = json.load(f)\n",
    "    print(\"Newest run folder:\", latest)\n",
    "    print(\"\\nBest configuration:\"); print(overall[\"best\"])\n",
    "    print(\"\\nAll runs:\"); \n",
    "    for r in overall[\"runs\"]:\n",
    "        print(r)\n",
    "else:\n",
    "    print(\"No runs found. Execute the training cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb296a7",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Plots & Discussion\n",
    "\n",
    "- Open the `runs/<timestamp>` folder and insert the `*_plots.png` here (Insert → Image).\n",
    "- Discuss observations (convergence, stability, steps trend).\n",
    "- Explain why your chosen (α, ε) performed best.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
